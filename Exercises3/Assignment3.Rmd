---
title: "Exercises Topic 5 and 6"
subtitle: "Lifetime Data Analysis - Autumn 2021"
author: "Alexander and Ulrik"
date: "`r format(Sys.time(), '%d %B, %Y')`"
params: 
  show_code: FALSE
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    theme: readable
    highlight: textmate
    number_sections: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F)
#setwd("/home/ajo/gitRepos/lifetime/Exercises3")
rm(list = ls())
library(KMsurv)
library(rms)
library(survival)
library(FHtest)
library(GofCens)
```

# Exercise 1
The data frame $\textbf{tongue}$ of the R package $\textbf{KMsurv}$ contains the survival times (in weeks) of 80 patients with oral cancer. The objective of this exercise is to study the possible relation of this cancer with the tumour DNA profile, which is either aneuploid (type 1) or diploid (type 2) .

```{r, results = "hide"}
data(tongue)
tongue$type <- factor(tongue$type)
```


## 1.a)

The survival curves are plotted below. Observe that the survival of the aneuploid tumour is greater than the survival of the diploid tumour. As the survival curves do not go to zero there is right censoring in both groups.

```{r}
s <- with(tongue, Surv(time, delta))
t <- npsurv(s ~ type, tongue)

par(font = 2, font.axis = 2, font.lab = 4, las = 1, mar = c(5, 5, 4, 2))
survplot(t, ylab = expression(bold(hat(S)(t))), col = 1:2, lwd = 3, conf = "none")
title("Survival functions according to tumour DNA profile")
```

## 1.b) 

The logrank test is used to test the hypothesis that survival is not related to tumour type. The hypothesis that is tested can be formulated as 
$$
\begin{equation}
        H_0: S_1(t) = S_2(t) \text{ vs. } H_1: S_1(t) \neq S_2(t),
\end{equation}
$$
    
where $S_1(t)$ and $S_2(t)$ refer to the survival curves of tumour type 1 and 2 respectively. 
    
The result from the logrank test is a $Z$-value of 1.7 and a $p$-value of $0.0949$, which means that we would conclude not to reject $H_0$ when choosing a significance level of (for example) $0.05$ for the $p$-value. This means that, according to the logrank test, there is not enough evidence to conclude that the tumour DNA profile is related to the survival of the cancer patients, i.e. one does not conclude that one of the tumour profiles leads to more severe cancer. 

```{r}
s2 <- with(tongue, Surv(time, delta) ~ type)
FHtestrcc(s2)
```

## 1.c)

The log-logistic regression model is fitted with the single covariate 'Tumour type'. This model is used to test the same hypothesis as in $\textbf{b)}$. In this case, the null and alternative hypothesis can be formulated as 
$$
  H_0: \gamma_1 = 0 \text{ vs. } H_1 : \gamma_1 \neq 0,
$$
where $\gamma_1$ is the covariate coefficent for tumour DNA profile in the model. The regression gives $\hat{\gamma}_1 = -0.79$ with $p$-value 0.051, which gives significant evidence to reject the null hypothesis with a level of $\alpha = 0.05$. Thus, the test suggests that DNA profile has an impact on the survival time of cancer patients. The negative value of the parameter estimate suggests that the diploid tumour profile is non-protective, i.e. that it lowers the survival of a person. This will be more closely examined in the next part of the problem. 

```{r}
loglogistic <- survreg(s ~ type, data = tongue, dist = "loglogistic")
summary(loglogistic)
```

## 1.d)
Since the log-logistic model can be viewed as a proportional odds model,
the odds ratio $\exp \{ - \boldsymbol{\beta'Z} \} = \exp \{ \boldsymbol{\gamma'Z}/\sigma \}$
indicates how the odds to survive changes with respect to covariates $\textbf{Z}$
compared to $\textbf{Z = 0}$.
For this model a patient with DNA profile diploid has a survival odds `r round(with(loglogistic, exp(coefficients[2] / scale)), 2)`
times the survival of a patient with DNA profile aneuploid. This means that the odds of surviving with the diploid profile is `r round(with(loglogistic, exp(coefficients[2] / scale)), 2)*100`\% of the odds of surviving with the aneuploid profile. 

Similarly, the acceleration factor $\exp \{ \boldsymbol{-\gamma'Z} \}$ describes the change in time scale compared to the baseline 
$\textbf{Z = 0}$. The value of the acceleration factor in this case is `r round(with(loglogistic, exp(-coefficients[2])), 3)`. This means that the death of a person with a diploid profile is accelerated by `r round(with(loglogistic, exp(-coefficients[2])), 3)` compared to the death of a person with a aneuploid profile. For example, considering medians, this means that the median of a person with an aneuploid profile is estimated to being `r round(with(loglogistic, exp(-coefficients[2])), 3)` larger than the median of a person with a diploid profile, which fits nicely with the survival curves we have seen earlier. 

```{r}
with(loglogistic, exp(coefficients[2] / scale))  # Odds ratio.
with(loglogistic, exp(-coefficients[2]))  # Acceleration factor.
```

## 1.e) 

The residuals of the log-logistic regression model are plotted below. As one can see, the standard logistic distribution seems to fit the residual KM-estimate well, which can be used as an indication that the log-logistic model is appropriate for this data. This is because the standard logistic distribution seems a reasonable choice for the error $W$. 

```{r}
loglo.pred <- predict(loglogistic, type = "linear")
resids.loglo <- (log(tongue$time) - loglo.pred) / loglogistic$scale

par(font = 2, font.axis = 2, font.lab = 2, las = 1, mar = c(5, 5, 4, 2))
plot(survfit(Surv(resids.loglo, tongue$delta) ~ 1), col = c(1,2,2), xlab = "Residuals",
     ylab = expression(bolditalic(hat(S)(t))),
     lty = 1, lwd = 3, yaxs = "i", xaxs = "i", bty = "n")
title("Residuals of the log-logistic Regression Model")
curve(plogis(x, lower.tail = F), from = min(resids.loglo), to = max(resids.loglo), col = 3, lwd = 3,
      add = TRUE)
legend("bottomleft", c("KM estimate", "95% - CI", "Stand. Logistic Distribution"),
       col = c(1, 2, 3), lty = c(1, 2, 1), lwd = 3, bty = "n")
```

# Exercise 2

Following, we will generate survival times from a log-normal distribution and check whether the Weibull or the log-logistic distribution fit better to the data. 

## 2.a)

300 survival times from a log-normal distribution with parameters $\mu = 2$ and $\sigma = 1$ are generated below. 

```{r, echo = T}
set.seed(1)
mu <- 2
sigma <- 1
location <- log(mu^2 / sqrt(sigma^2 + mu^2))
shape <- sqrt(log(1 + (sigma^2 / mu^2)))
RVT <- rlnorm(300, meanlog = location, sdlog = shape)
# https://en.wikipedia.org/wiki/Log-normal_distribution#Arithmetic_moments
# https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/
```


## 2.b) 

300 censoring times from an exponential distribution with mean 20 are generated below. 

```{r, echo = T}
RVC <- rexp(300, rate = 1/20)
```

## 2.c)

The variables $Y = \min(T, C)$ and $\delta = \mathbf{1}_{\{T\leq C\}}$ are created below. The table below shows the counts of exact failure times and censoring times.

```{r, echo = T}
obs <- pmin(RVT, RVC)
cens <- as.numeric(RVT <= RVC)
(tab <- table(cens))
```

The proportion of right-censored survival times is thus `r round(tab[[1]]/(tab[[1]]+tab[[2]]), 3)`.

## 2.d)

The cumulative hazard plots for the Weibull and the log-logistic distributions are plotted below. It looks like the log-logistic distribution fits the data better than the Weibull model, since the latter is clearly a bad fit. 

```{r, results="hide"}
cumhazPlot(obs, cens, col = 4, distr = c("wei", "loglo"), ggplo = T)
```

# Exercise 3

Assume that the model assumptions for the Cox proportional hazards model holds for a continuous survival time $T$ with covariates $\textbf{Z} = (Z_1, \ldots, Z_p)'$, i.e., that,
$$
\begin{equation*}
        \lambda(t; \textbf{z}) = \lambda_0(t) \exp (\boldsymbol{\beta'z}), 
\end{equation*}
$$
but that the survival times are grouped in the intervals $[0 = a_0, a_1), \ldots, [a_{g-1}, a_g)$.
The corresponding hazards are defined as 
$$
\begin{equation*}
        \lambda_j(\textbf{z}) = P(T < a_j |T \geq a_{j-1}; \textbf{z}), \ j = 1, \ldots, g.
\end{equation*}
$$
Then we can write 
$$
\begin{align*}
        1 - \lambda_j(\textbf{z}) &= P(T \geq a_j | T \geq a_{j-1}; \textbf{z}) \\
                                  &= \frac{P(T \geq a_j, T \geq a_{j-1} ; \textbf{z})}{P(T \geq a_{j-1}; \textbf{z})} \\
                                  &= \frac{P(T \geq a_j; \textbf{z})}{P(T \geq a_{j-1}; \textbf{z})}.
\end{align*}
$$
First we observe that 
$$
\begin{align*}
        P(T \geq a_j ; \textbf{z}) &= S_\textbf{z}(a_j) \\\
                                   &= \exp (- \Lambda_\textbf{z}(a_j)) \\
                                   &= \exp (-(\int_{a_0}^{a_1}\lambda_0(t)\exp (\boldsymbol{\beta'z})dt + \ldots + \int_{a_{j-1}}^{a_j}\lambda_0(t)\exp(\boldsymbol{\beta'z})dt)) \\
                                   &= \exp (-(\int_{a_0}^{a_1}\lambda_0(t)dt + \ldots + \int_{a_{j-1}}^{a_j}\lambda_0(t)dt)\exp (\boldsymbol{\beta'z}) \\
                                   &= \left( \exp(-\Lambda_\textbf{0}(a_j)) \right)^{\exp (\boldsymbol{\beta'z})} \\
                                   &= (P(T \geq a_j ; \textbf{0}))^{\exp (\boldsymbol{\beta'z})}.
\end{align*}
$$
The exact same argument for $P(T \geq a_{j-1} ; \textbf{z})$ gives us 
$$
\begin{align*}
        1 - \lambda_j(\textbf{z}) &= \left( \frac{P(T \geq a_j; \textbf{0})}{P(T \geq a_{j-1}; \textbf{0})} \right)^{\exp (\boldsymbol{\beta'z})} \\
                                  &= (1 - \lambda_j(\textbf{0}))^{\exp (\boldsymbol{\beta'z})}
\end{align*}
$$
or equivalently
$$
\begin{equation*}
        \log (1 - \lambda_j(\textbf{z})) = \log (1 - \lambda_j) \exp (\boldsymbol{\beta'z}).
\end{equation*}
$$

# Exercise 4

The data frame $\textbf{hodg}$ of the $\textbf{KMsurv}$ package contains the times until relapse or death of 43 lymphoma patients that underwent a bone marrow transplant. 

## 4.a)

The variables **gtype** and **dtype** are converted into factors. 

```{r}
data(hodg)
str(hodg)
hodg$gtype <- factor(hodg$gtype, labels = c("allo", "auto"))
hodg$dtype <- factor(hodg$dtype, labels = c("NonHodgk", "Hodgk"))
str(hodg)
```

## 4.b

Survival curves corresponding to the four combinations of graft and disease types are plotted below. 

```{r}
srem <- with(hodg, Surv(time, delta))
svf <- survfit(srem ~ gtype + dtype, data = hodg)

par(las = 1, font = 2, font.axis = 2, font.lab = 4, xaxs = "i", yaxs = "i",
    mar = c(5, 5, 4, 2), bty = "l", cex.lab = 1.5, cex.axis = 1.25)
plot(svf, conf.int = F, lwd = 2, col = 1:4, lty = 1:4, xlab = "Time to death or relapse [days]",
     ylab = expression(bolditalic(hat(S)(t))), ylim = c(0,1), xlim = c(0, 1500))
axis(1, at = seq(0, 2000, 250))
axis(2, at = seq(0, 1, 0.1))
title("Survival Functions of All Combinations of Graft and Disease Types")
legend("bottomright", legend = levels(hodg$gtype:hodg$dtype),
       col = 1:4, lty = 1:4, lwd = 2, bty = "n")
```

The leftmost number in the legend is **gtype** and the rightmost number is **dtype**. The $x$-axis is limited to 1500 in order to see more clearly what is happening in the beginning. 

It looks like the different combinations of graft and disease types yield significantly different survival times. Considering longevity, the combination of allogenic graft type and Non Hodgkin lymphoma yields the largest survival, closely followed by autologous graft type and Hodgkins disease. The combination of allogenic graft type and Hodgkins disease seams to yield very low survival. Note that all combinations have a right-censored last time in the data set, except the combination of allogenic graft type and Hodgkins disease, which has a survival that ends in zero, because the last time is a failure time. 

## 4.c)

Fit the proportional hazards model that includes graft type, disease type, the interaction of both and the Karnofsky index. 


```{r}
proph <- coxph(srem ~ gtype + dtype + gtype:dtype + score, data = hodg)
summary(proph)
```

As is seen from the output above, all three tests shows that the model is significantly better than the null model The Karnofsky index (`score`) is significant. Moreover, when choosing a significance level of $\alpha = 0.05$, the parameter estimate comparing Hodgkins disease to non Hodgkins disease is significant. 

Since the parameter estimation for the Karnofsky index is negative, the model is predicting that an increase in the Karnofsky score, while all other covariates are kept static, decreases the instantaneous risk of death or relapse. More precisely, for a unitary increase in the Karnofsky index, an individual with the same profile (except the change in the score) will have an instantaneous risk that is $\approx e^{-0.05441} \approx$ `r round(exp(proph$coefficients[[3]]), 2)` times the individual before the increase. On the contrary, having Hodgkins disease is predicted as being non-protective compared to not having it, when considering the other covariates as static. More precisely, having the disease will yield an instantaneous risk of $\approx e^{1.68314} \approx$ `r round(exp(proph$coefficients[[2]]), 2)` times the instantaneous risk when not having the disease, for an individual with the same profile (the remaining covariates). Similar interpretations can be done with the two other covariates, but this is excluded since they are not statistically significant. 

## 4.d)

The hazard ratio measures the comparative instantaneous risk of death.
Since there exists interaction between the graft type and the disease type,
two hazard ratios are computed, one for patients with non Hodgkin lymphoma,
and one for patients with Hodgkins disease. The 
hazard ratios are 1.704 and 0.326 respectively.
This means that patients receiving an autologous graft have 1.704 times higher 
instantaneous risk of dying compared to patients with allogenic graft type, given that the disease type is non Hodgkin lymphoma
and the Karnofsky index is the same. 
Similarly, patients receiving an autologous graft have 0.326 times lower 
instantaneous risk of dying compared to patients with allogenic graft type, given that the disease type is Hodgkins disease
and the Karnofsky index is the same. 

```{r}
library(Epi)
ctmat <- matrix(c(1,0,0,0,1,0,0,1), byrow = TRUE, nr = 2)
HRmat <- round(ci.lin(proph, ctr.mat = ctmat, Exp = TRUE), 3)[, c(1, 5:7)]
rownames(HRmat) <- c("HR| Non Hodgkin lymphoma", "HR| Hodgkins disease")
colnames(HRmat) <- c("logHR", "HR", "Lower 95%", "Upper 95%")
HRmat
```



## 4.e)

The proportional hazards assumption is checked, using the Schoenfeld residuals.

```{r}
schres <- residuals(proph, "schoenfeld")

prop.haz.test <- cox.zph(proph)
```

```{r}
par(mfrow = c(2, 3), font = 2, font.lab = 4, font.axis = 2, las = 1,
    cex.lab = 1.3, cex.axis = 1.2)
plot(prop.haz.test, lwd = 2)
```

The Schoenfeld residuals are plotted above. None of the covariates look like they have a line with slope zero, i.e. it looks like they all exhibit a systematic pattern. This means that, based on the plot, the proportional hazards assumption does not hold for any of the covariates. 

```{r}
prop.haz.test
```

The $p$-values in the table above are $p$-values from a two-sided test of slope $= 0$ in the Schoenfeld residuals plotted earlier. To a significance level of $\alpha = 0.05$, the only null hypothesis to be rejected is the one concerning the interaction term. 

Despite the results from the tests above, we would still conclude that the proportional hazards assumption does not hold for any of the covariates, which means that the model is not suitable in this case. 

## 4.f)

Concerning the estimation of the four model parameters, are there any influential observations?

A transformation of the score residuals for each of the four coefficients is plotted below. More precisely, each residual that is plotted is the approximate change in the coefficient vector if the observation in question is dropped, scaled by the standard error of the coefficients. 

```{r}
dfbet <- residuals(proph, type = "dfbetas")

par(mfrow = c(2, 2), font = 2, font.lab = 4, font.axis = 2, las = 1,
    cex.lab = 1.3, cex.axis = 1.2)
for (i in 1:4) {
  plot(dfbet[, i], pch = 16, ylab = "")
  title(names(coef(proph))[i])
  axis(1, at = seq(5, 45, 5))
}
```

In order to identify which observations are influential, text describing each residual is plotted alongside the points. They can also be identified manually by clicking on the plots using the `identify` function in R. 

```{r}
par(mfrow = c(1,1), font = 2, font.lab = 4, font.axis = 2, las = 1, cex.lab = 1.3,
    cex.axis = 1.2)
plot(dfbet[, 1], pch = 16, ylab = "",xlim = c(-20, 60))
title(names(coef(proph))[1])
axis(1, at = seq(5, 45, 5))
text(dfbet[, 1],
         labels = paste0("Row: ", rownames(hodg), "; Time: ", hodg$time,
                         "; Cens: ", hodg$delta, "; gtype: ", hodg$gtype))

par(mfrow = c(1,1), font = 2, font.lab = 4, font.axis = 2, las = 1, cex.lab = 1.3,
    cex.axis = 1.2)
plot(dfbet[, 2], pch = 16, ylab = "", xlim = c(-20, 60))
title(names(coef(proph))[2])
axis(1, at = seq(5, 45, 5))
text(dfbet[, 2],
         labels = paste0("Row: ", rownames(hodg), "; Time: ", hodg$time,
                         "; Cens: ", hodg$delta, "; dtype: ", hodg$dtype))

par(mfrow = c(1,1), font = 2, font.lab = 4, font.axis = 2, las = 1, cex.lab = 1.3,
    cex.axis = 1.2)
plot(dfbet[, 3], pch = 16, ylab = "", xlim = c(-20, 60))
title(names(coef(proph))[3])
axis(1, at = seq(5, 45, 5))
text(dfbet[, 3],
         labels = paste0("Row: ", rownames(hodg), "; Time: ", hodg$time,
                         "; Cens: ", hodg$delta, "; score: ", hodg$score))

par(mfrow = c(1,1), font = 2, font.lab = 4, font.axis = 2, las = 1, cex.lab = 1.3,
    cex.axis = 1.2)
plot(dfbet[, 4], pch = 16, ylab = "", xlim = c(-20, 60), ylim = c(-0.3, 0.3))
title(names(coef(proph))[4])
axis(1, at = seq(5, 45, 5))
text(dfbet[, 4],
         labels = paste0("Row: ", rownames(hodg), "; Time: ", hodg$time,
                         "; Cens: ", hodg$delta, "; gtype: ", hodg$gtype, "; dtype: ", hodg$dtype))
```

There are some influential observations. They can be found for large absolute values that deviate from zero in the plots above. Examples like row 1 and row 15 seem to be influential for several of the covariates. 

For example, row 1 

```{r}
hodg[1,]
```

has a large score and looks to be influential for both `gtypescore` and `dtypeHodgk`. Estimating the Cox model without the first row gives 

```{r}
summary(coxph(Surv(time, delta) ~ gtype + dtype + gtype:dtype + score, data = hodg[-1,]))
```

where we see that the hazard ratios for the two mentioned covariates change quite a bit. 
